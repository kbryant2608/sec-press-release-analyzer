# SEC EDGAR Press Release Analyzer

A **Python**â€“based pipeline and **Jupyter Notebook** for automating the retrieval, extraction, and analysis of Form 8â€‘K press releases (ExhibitÂ 99.1) from the SECâ€™s EDGAR system.

## ğŸ” Features

* **Tickerâ†’CIK Mapping:** Converts stock symbols into SEC Central Index Keys.
* **8â€‘K Filings Fetcher:** Downloads recent FormÂ 8â€‘K metadata via EDGARâ€™s submissions API.
* **Exhibit Extraction:** Identifies and pulls the correct ExhibitÂ 99.1 HTML (or equivalent) for each filing.
* **Text Cleaning & NLP:** Lowercases, strips boilerplate, then runs sentiment (VADER) and keyword (TFâ€‘IDF) analyses.
* **Data Export:** Compiles results into a `press_releases_summary.csv` for downstream reporting or visualization.

## ğŸš€ Quick Start

1. **Clone** the repo and navigate into it:

   ```bash
   git clone https://github.com/kbryant2608/sec-press-release-analyzer.git
   cd sec-press-release-analyzer
   ```
2. **Create a virtual environment** and **activate** it:

   ```bash
   python3 -m venv venv      # macOS/Linux
   source venv/bin/activate  # macOS/Linux

   python -m venv venv       # Windows PowerShell
   .\\venv\\Scripts\\Activate.ps1  # Windows
   ```
3. **Install** dependencies:

   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```
4. **Launch** JupyterLab and open the notebook:

   ```bash
   pip install jupyterlab ipykernel
   python -m ipykernel install --user --name=sec-analyzer-venv --display-name "Python (sec-analyzer)"
   jupyter lab
   ```
5. **Run** each step in `notebooks/sec_press_release_analyzer.ipynb` (StepÂ 1 through StepÂ 6).
6. **Find** `press_releases_summary.csv` in the `outputs/` folder.

## ğŸ“¦ Project Structure

```
sec-press-release-analyzer/
â”œâ”€â”€ notebooks/                # Jupyter notebook orchestration
â”‚   â””â”€â”€ sec_press_release_analyzer.ipynb
â”œâ”€â”€ src/                      # Modular Python code for each pipeline stage
â”‚   â”œâ”€â”€ ticker_to_cik.py
â”‚   â”œâ”€â”€ fetch_filings.py
â”‚   â”œâ”€â”€ parse_exhibits.py
â”‚   â”œâ”€â”€ text_analysis.py
â”‚   â””â”€â”€ export.py
â”œâ”€â”€ outputs/                  # CSV and other generated files
â”œâ”€â”€ requirements.txt          # Project dependencies
â”œâ”€â”€ .gitignore                # Ignored files
â””â”€â”€ README.md                 # This file
```

## ğŸ› ï¸ Customization

* **Tickers:** Modify the `tickers` list in StepÂ 2 of the notebook.
* **Filings Count:** Adjust `count_per_cik` in StepÂ 3.
* **Regex Patterns:** Update `src/parse_exhibits.py` if exhibit naming differs.
* **Keywords:** Change `top_n_keywords` in StepÂ 5 or `assemble_records()`.

## ğŸ¤ Contributing

1. Fork the repo and create a branch.
2. Submit a pull request with your improvements.

---

Â©Â 2025 SilentBillionAI | by Karissa Bryant
